@page "/"
@using faceoff.Core
@using System.Diagnostics

@inject faceoff.Core.FaceOffService FaceOffService

<h3>FaceOffCore Integration</h3> 

@inject ImageHandler IH
<div id="container" style="position: relative;">
    <CameraStreamer @ref=CameraStreamerReference
                Width=900
                Height=675
                OnRendered=OnRenderedHandler
                OnFrame=OnFrameHandler
                CameraID=@cameraId
                Style="width: 900px; height:675px; border: 10px solid black; border-radius: 2%;"
                Autostart />
    
    @foreach (var faceData in faceEmotionDataList) {
        <div class="frame" style="@faceData.TrackingStyle">
            <div class="emotion-container @faceData.EmotionClass" style="@faceData.ContainerStyle">
                    <div class="frame-content" style="@faceData.ColorStyle" />
                <div class="emotion-indicator">
                    <div class="emotion-text" style="color: @faceData.HtmlColor">
                        <span class="emotion-label">@faceData.MoodText</span>
                        <div class="emotion-confidence">@(faceData.Confidence > 0 ? $"{faceData.Confidence:P0}" : "")</div>
                    </div>
                    <div class="emotion-icon">@GetEmotionIcon(faceData.MoodText)</div>
                </div>
            </div>
        </div>
    }
</div>


@code
{
    private List<DetectedFace> faces = new();
    private List<FaceEmotionData> faceEmotionDataList = new();

    private CameraStreamer CameraStreamerReference;
    private string cameraId = null;

    private EmotionDetectionService _emotionService;

    protected override void OnInitialized()
    {
        _emotionService = new EmotionDetectionService("onnx_model.onnx");
        base.OnInitialized();
    }

    private async void OnRenderedHandler()
    {
        if (await CameraStreamerReference.GetCameraAccessAsync())
        {
            await CameraStreamerReference.ReloadAsync();
        }
    }

    // used to generate a float value declaring the similarity in X, Y coordinates between two faces
    @* private int CompareCoords(DetectedFace oldF, DetectedFace newF) {
        int absX = (int)Math.Abs(oldF.X - newF.X);
        int absY = (int)Math.Abs(oldF.Y - newF.Y); 
        return absX + absY;
    } *@

    // used to generate a float value declaring the similarity in X, Y coordinates between two faces
    private bool CloseCoord(DetectedFace oldF, DetectedFace newF) {
        int threshold = 50;
        int absX = (int)Math.Abs(oldF.X - newF.X);
        int absY = (int)Math.Abs(oldF.Y - newF.Y); 
        
        return (absX + absY < threshold) ? true : false;
    }

    private async void OnFrameHandler(string data)
    {
        data = data[(data.IndexOf(',') + 1)..];

        // Converts base64 string to byteArray
        byte[] byteArray = System.Convert.FromBase64String(data);

        @* faces = FaceOffService.CameraImageFeed(byteArray); *@
        faceEmotionDataList.Clear(); // Clear previous data

        List<FaceEmotionData> newFaceEmotionDataList = new();
        List<DetectedFace> newFaces = FaceOffService.CameraImageFeed(byteArray);;

        foreach (var face in newFaces)
        {
            Console.WriteLine($"FACES FOUND AT ({face.X}, {face.Y}), size ({face.Width}x{face.Height}), confidence: {face.Confidence}");

            var emotionResult = await _emotionService.DetectEmotion(face, byteArray);

            var faceData = new FaceEmotionData
            {
                Confidence = emotionResult.Confidence,
                MoodText = char.ToUpper(emotionResult.Emotion[0]) + emotionResult.Emotion.Substring(1),
            };

            // Set styles based on emotion **before** tracking the frame
            switch (emotionResult.Emotion.ToLower())
            {
                case "happy":
                    faceData.HtmlColor = "#4CAF50";
                    faceData.EmotionClass = "emotion-happy";
                    faceData.ColorStyle = "border-color: #4CAF50";
                    break;
                case "sad":
                    faceData.HtmlColor = "#2196F3";
                    faceData.EmotionClass = "emotion-sad";
                    faceData.ColorStyle = "border-color: #2196F3";
                    break;
                case "angry":
                    faceData.HtmlColor = "#F44336";
                    faceData.EmotionClass = "emotion-angry";
                    faceData.ColorStyle = "border-color: #F44336";
                    break;
                default:
                    faceData.HtmlColor = "#9E9E9E";
                    faceData.EmotionClass = "emotion-neutral";
                    faceData.ColorStyle = "border-color: #9E9E9E";
                    break;
            }

            // Now track the frame using the updated HtmlColor
            faceData.TrackingStyle = TrackImage(
                (int)(face.X + face.X / 4), 
                (int)(face.Y + face.Y / 4), 
                (int)face.Width, 
                (int)face.Height, 
                faceData.HtmlColor
            );

            newFaceEmotionDataList.Add(faceData);
        }
        
        // arrange new list on similarity to old list
        @* if (faceEmotionDataList.Any() && newFaceEmotionDataList.Any()) {

            // for each element in the old list order the new list to fit that old element the best
            for (int i=0; i<faces.Count && i<newFaces.Count; i++) {
                List<int>similarityScores = new List<int>();

                for (int j=0+i; j<newFaces.Count; j++) {
                    similarityScores.Add(CompareCoords(faces[i], newFaces[j]));
                }

                // assign closest similarity to index i
                if (similarityScores.Any()) {
                   // find closest match for index

                    int smallest = similarityScores[0];
                    int index = 0;
                    for (int s=0; s<similarityScores.Count; s++) {
                        if (similarityScores[s] < smallest) {
                            smallest = similarityScores[s];
                            index = s;
                        }
                    }

                    // move to that index
                    var temp = newFaceEmotionDataList[smallest];
                    newFaceEmotionDataList.RemoveAt(smallest);
                    newFaceEmotionDataList.Insert(smallest, temp);
                }
            }
        } *@

        var sw = new Stopwatch();
        sw.Start();

        if (faceEmotionDataList.Any() && newFaceEmotionDataList.Any()) {
            for (int i=0; i<faces.Count && i<newFaces.Count; i++) {
                for (int j=0+i; j<newFaces.Count; j++) {
                    if (CloseCoord(faces[i], newFaces[j])) {
                        var temp = newFaceEmotionDataList[j];
                        newFaceEmotionDataList.RemoveAt(j);
                        newFaceEmotionDataList.Insert(i, temp);
                    }
                }
            }
        }

        sw.Stop();
        Console.WriteLine($"Time to sort: {sw.ElapsedMilliseconds}");

        faces = newFaces;
        faceEmotionDataList = newFaceEmotionDataList;

        if (!faces.Any())
        {
            faceEmotionDataList.Clear(); // Reset display when no faces detected
        }

        InvokeAsync(StateHasChanged);
    }



    private string TrackImage(int x, int y, int width, int height, string HtmlColor)
    {
        return $"position:absolute; left:{x}px; top:{y}px; width:{width}px; height:{height}px; border: 2px solid {HtmlColor};";
    }

    private string GetEmotionIcon(string emotion) => emotion.ToLower() switch
    {
        "happy" => "😊",
        "sad" => "😢",
        "angry" => "😠",
        "surprise" => "😮",
        "fear" => "😨",
        "disgust" => "🤢",
        _ => "😐"
    };

    public void Dispose()
    {
        _emotionService?.Dispose();
    }
}
